---
phase: 03-chat-screen
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/app/router/routes.dart
  - lib/features/profile/presentation/screens/profile_screen.dart
  - lib/features/chat/presentation/providers/chat_ui_provider.dart
  - lib/features/chat/application/chat_service.dart
  - lib/features/chat/presentation/providers/chat_stream_provider.dart
  - lib/features/chat/presentation/screens/chat_screen.dart
autonomous: true

must_haves:
  truths:
    - "Tapping the LoglyAI FAB on the profile screen navigates to the chat screen"
    - "Non-pro users see the RevenueCat paywall before reaching the chat screen"
    - "The bridge provider translates ChatStreamState changes into ChatController insert/update/remove operations"
    - "The stop button cancels an in-progress stream and preserves partial text"
  artifacts:
    - path: "lib/app/router/routes.dart"
      provides: "ChatRoute typed GoRoute at /chat"
      contains: "ChatRoute"
    - path: "lib/features/chat/presentation/providers/chat_ui_provider.dart"
      provides: "ChatUiStateNotifier bridging ChatStreamState to InMemoryChatController"
      contains: "ChatUiStateNotifier"
    - path: "lib/features/chat/presentation/screens/chat_screen.dart"
      provides: "Scaffold placeholder for Chat widget (completed in Plan 02)"
      contains: "ChatScreen"
  key_links:
    - from: "lib/features/profile/presentation/screens/profile_screen.dart"
      to: "lib/app/router/routes.dart"
      via: "const ChatRoute().go(context)"
      pattern: "ChatRoute.*go"
    - from: "lib/features/chat/presentation/providers/chat_ui_provider.dart"
      to: "lib/features/chat/presentation/providers/chat_stream_provider.dart"
      via: "ref.listen(chatStreamStateProvider)"
      pattern: "chatStreamStateProvider"
---

<objective>
Wire the chat screen route, navigation from the profile FAB, the Riverpod-to-ChatController bridge provider, and stream cancellation support.

Purpose: Establish the navigation path and state bridge that all subsequent UI work depends on. The bridge provider is the most architecturally complex piece of Phase 3 -- it translates `ChatStreamState` emissions into `InMemoryChatController` operations (insert, update, remove messages) that `flutter_chat_ui`'s `Chat` widget observes.

Output: A navigable `/chat` route, the bridge provider, stream cancellation in the service layer, and a placeholder `ChatScreen` widget.
</objective>

<execution_context>
@/Users/robsnider/.claude/get-shit-done/workflows/execute-plan.md
@/Users/robsnider/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-chat-screen/03-CONTEXT.md
@.planning/phases/03-chat-screen/03-RESEARCH.md
@.planning/phases/02-stream-client/02-02-SUMMARY.md

Key existing files to read before implementing:
@lib/app/router/routes.dart -- Route definitions (add ChatRoute here)
@lib/features/profile/presentation/screens/profile_screen.dart -- _InsightsFab to update navigation
@lib/features/chat/presentation/providers/chat_stream_provider.dart -- ChatStreamStateNotifier (bridge listens to this)
@lib/features/chat/domain/chat_stream_state.dart -- ChatStreamState, ChatConnectionStatus, ChatCompletedStep
@lib/features/chat/application/chat_service.dart -- Add cancellation support
@lib/features/chat/application/typewriter_buffer.dart -- TypewriterBuffer lifecycle
@lib/features/auth/presentation/providers/auth_state_provider.dart -- currentUserProvider for user ID
</context>

<tasks>

<task type="auto">
  <name>Task 1: Chat route, navigation wiring, and placeholder screen</name>
  <files>
    lib/app/router/routes.dart
    lib/features/profile/presentation/screens/profile_screen.dart
    lib/features/chat/presentation/screens/chat_screen.dart
  </files>
  <action>
    1. Create `lib/features/chat/presentation/screens/chat_screen.dart`:
       - A `ConsumerStatefulWidget` named `ChatScreen` with a Scaffold, AppBar titled "LoglyAI", and a `Center(child: Text('Chat screen placeholder'))` body.
       - This is a temporary placeholder that Plan 02 will replace with the full Chat widget.

    2. Add a `ChatRoute` to `lib/app/router/routes.dart`:
       - Add `@TypedGoRoute<ChatRoute>(path: '/chat')` as a top-level route (NOT inside the shell route -- the chat screen should be a full-screen push, not a tab).
       - The route class: `class ChatRoute extends GoRouteData with $ChatRoute` returning `const ChatScreen()`.
       - Add the import for `chat_screen.dart`.

    3. Run `fvm dart run build_runner build --delete-conflicting-outputs` to generate the route code.

    4. Update `lib/features/profile/presentation/screens/profile_screen.dart`:
       - In the `_InsightsFab._onPressed` method, replace the "AI Insights coming soon!" snackbar with `const ChatRoute().go(context)`.
       - The `else` branch (non-pro) already shows the paywall, so no changes needed there.
       - Add the import for `routes.dart` if not already imported (it should already be imported via GoRouter usage, but verify).
       - Import `routes.dart` from `package:logly/app/router/routes.dart`.
  </action>
  <verify>
    - `fvm flutter analyze` passes clean
    - The generated `routes.g.dart` includes `ChatRoute` with `$appRoutes` containing the `/chat` route
    - Profile screen imports and references `ChatRoute`
  </verify>
  <done>
    ChatRoute exists at `/chat`, profile FAB navigates pro users to `/chat`, non-pro users see paywall. ChatScreen placeholder renders.
  </done>
</task>

<task type="auto">
  <name>Task 2: Stream cancellation and ChatController bridge provider</name>
  <files>
    lib/features/chat/application/chat_service.dart
    lib/features/chat/presentation/providers/chat_stream_provider.dart
    lib/features/chat/presentation/providers/chat_ui_provider.dart
  </files>
  <action>
    **Part A: Add stream cancellation to ChatService and ChatStreamStateNotifier**

    1. In `lib/features/chat/application/chat_service.dart`:
       - Change the `_executeStream` method to accept a `StreamSubscription` tracking mechanism. The simplest approach: make `sendQuestion` return early if a cancellation flag is set.
       - Add a `Completer<void>? _cancelCompleter` field to `ChatService`. When cancel is called, complete it. In `_executeStream`, check `_cancelCompleter?.isCompleted` before processing each event.
       - Actually, a simpler pattern: add a `cancel()` method that sets a `_cancelled = true` flag. In `_executeStream`, check `_cancelled` after each `await for` iteration. On cancel, emit a `completed` state with the current `displayText` (partial text preserved).
       - Reset `_cancelled = false` at the start of each `sendQuestion` call.

    2. In `lib/features/chat/presentation/providers/chat_stream_provider.dart`:
       - Add a `cancelStream()` method to `ChatStreamStateNotifier` that:
         a. Calls `_service.cancel()` to signal cancellation
         b. Sets state to `completed` with current `displayText` and `fullText` preserved
       - This gives the UI a way to stop streaming while keeping partial text visible.

    **Part B: Create the bridge provider**

    3. Create `lib/features/chat/presentation/providers/chat_ui_provider.dart`:
       - Import `flutter_chat_core` (for `InMemoryChatController`, `Message`, `User`), `uuid`, `riverpod_annotation`, and the chat stream provider.
       - Define `const kLoglyAiUserId = 'logly-ai'` at the top of the file.

       - Create a `@Riverpod(keepAlive: true)` class `ChatUiStateNotifier extends _$ChatUiStateNotifier`:
         - State type: `InMemoryChatController`
         - In `build()`:
           a. Create `_controller = InMemoryChatController()`
           b. Set up `ref.listen(chatStreamStateProvider, _onStreamStateChanged)` to react to stream state changes
           c. `ref.onDispose(() => _controller.dispose())`
           d. Return `_controller`

         - Track internal state:
           - `String? _currentAiMessageId` -- ID of the current AI message in the controller
           - `String? _pendingUserQuery` -- The user's question text (for error restoration)
           - `String? _pendingUserMessageId` -- ID of the user message (for error removal)
           - `DateTime? _stepStartTime` -- When first step event arrived (for summary duration)
           - `bool _stepsCollapsed = false` -- Whether steps have been collapsed to summary

         - `void sendMessage(String query)` method:
           a. Generate user message ID with `const Uuid().v4()`
           b. Insert `Message.text(id: userMsgId, authorId: currentUserId, text: query, createdAt: DateTime.now())` into controller
           c. Store `_pendingUserQuery = query` and `_pendingUserMessageId = userMsgId`
           d. Generate AI message ID with `const Uuid().v4()`, store as `_currentAiMessageId`
           e. Insert `Message.textStream(id: aiMsgId, authorId: kLoglyAiUserId, streamId: const Uuid().v4(), createdAt: DateTime.now())` into controller
           f. Reset `_stepStartTime = null` and `_stepsCollapsed = false`
           g. Call `ref.read(chatStreamStateProvider.notifier).sendQuestion(query)`

         - `void _onStreamStateChanged(ChatStreamState? previous, ChatStreamState next)`:
           Core logic -- map stream state transitions to controller operations:

           a. If `_currentAiMessageId == null`, return (no active AI message to update).

           b. **streaming/completing states** -- Update the existing TextStreamMessage's metadata:
              - Find the current message in `_controller.messages` by ID
              - If it's a `TextStreamMessage`, update it via `_controller.updateMessage(oldMsg, newMsg)` with:
                - `metadata: { 'steps': next.completedSteps.map((s) => s.name).toList(), 'currentStepName': next.currentStepName, 'currentStepStatus': next.currentStepStatus, 'displayText': next.displayText, 'streamStatus': next.status.name, 'stepsCollapsed': _stepsCollapsed, 'stepDurationMs': _stepStartTime != null ? DateTime.now().difference(_stepStartTime!).inMilliseconds : null }`
              - Track `_stepStartTime` on first step event (when `next.currentStepName != null && _stepStartTime == null`)
              - Detect steps collapse: when `next.completedSteps.isNotEmpty && next.currentStepName == null && next.displayText.isNotEmpty && !_stepsCollapsed`, set `_stepsCollapsed = true`

           c. **completed state** -- Replace TextStreamMessage with TextMessage:
              - Find the TextStreamMessage by ID
              - Call `_controller.updateMessage(oldMsg, Message.text(id: _currentAiMessageId!, authorId: kLoglyAiUserId, text: next.fullText, createdAt: oldMsg.createdAt, metadata: { 'steps': next.completedSteps.map((s) => s.name).toList(), 'stepsCollapsed': true, 'stepCount': next.completedSteps.length, 'stepDurationMs': _stepStartTime != null ? DateTime.now().difference(_stepStartTime!).inMilliseconds : null }))`
              - Clear `_currentAiMessageId`, `_pendingUserQuery`, `_pendingUserMessageId`

           d. **error state** -- Remove user message, insert error, restore input:
              - If `_pendingUserMessageId != null`, find and remove the user message from controller
              - If `_currentAiMessageId != null`, find and remove the AI message from controller
              - Insert a `Message.system(id: Uuid().v4(), authorId: 'system', text: next.errorMessage ?? 'Something went wrong. Please try again.', createdAt: DateTime.now())` as the error message
              - Store `_lastErrorQuery = _pendingUserQuery` for input restoration (expose via getter)
              - Clear `_currentAiMessageId`, `_pendingUserQuery`, `_pendingUserMessageId`

         - Add getter: `String? get lastErrorQuery => _lastErrorQuery`
         - Add method: `void clearLastErrorQuery() => _lastErrorQuery = null`

         - `void clearMessages()` method to reset conversation:
           a. Call `_controller.setMessages([])`
           b. Clear all tracking variables
           c. Call `ref.read(chatStreamStateProvider.notifier).resetConversation()`

         - Need to get the current user ID. Read it from `currentUserProvider` in the build method and store as a field.

    4. Run `fvm dart run build_runner build --delete-conflicting-outputs` to generate the provider code.

    **Important implementation notes from research:**
    - Always fetch the current message from `_controller.messages.firstWhere((m) => m.id == targetId)` before calling `updateMessage` -- never use a stale reference.
    - Only replace TextStreamMessage with TextMessage when status is `completed` (NOT `completing`).
    - The `metadata` map on TextStreamMessage is the channel for passing step data to the custom builder (Plan 02 will read it).
    - Use `await` on `insertMessage`, `updateMessage`, `removeMessage` -- they are async.
  </action>
  <verify>
    - `fvm flutter analyze` passes clean
    - `chatUiStateProvider` is generated and returns `InMemoryChatController`
    - `ChatService` has a `cancel()` method
    - `ChatStreamStateNotifier` has a `cancelStream()` method
  </verify>
  <done>
    Bridge provider translates all ChatStreamState transitions (connecting, streaming, completing, completed, error) into ChatController operations. Cancel support allows stopping a stream in progress. Error handling removes user message and restores query text for re-editing.
  </done>
</task>

</tasks>

<verification>
1. `fvm flutter analyze` -- zero errors, zero warnings
2. `fvm dart run build_runner build --delete-conflicting-outputs` -- generates cleanly
3. Route `/chat` is registered in `$appRoutes`
4. Profile FAB `_onPressed` navigates to `ChatRoute` for pro users
5. Bridge provider exists with `sendMessage`, `clearMessages`, `cancelStream` (via notifier) methods
</verification>

<success_criteria>
- Navigating to `/chat` from profile FAB works (pro users go to chat, non-pro see paywall)
- Bridge provider correctly maps stream state changes to ChatController operations
- Cancel support stops streaming and preserves partial text
- Error state removes user message and exposes query for input restoration
- All code analyzes clean
</success_criteria>

<output>
After completion, create `.planning/phases/03-chat-screen/03-01-SUMMARY.md`
</output>
