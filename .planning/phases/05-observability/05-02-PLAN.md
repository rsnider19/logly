---
phase: 05-observability
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - supabase/functions/chat/sqlGenerator.ts
  - supabase/functions/chat/responseGenerator.ts
  - supabase/functions/chat/pipeline.ts
autonomous: true

must_haves:
  truths:
    - "Every chat request produces a telemetry log record with generated SQL"
    - "Token usage counts are captured from OpenAI API responses for both SQL generation and response generation"
    - "Three duration measurements are captured: NL-to-SQL, SQL execution, response generation"
    - "TTFB (time to first byte) is captured from request start to first text delta"
    - "Partial failures still log available metrics with nulls for incomplete steps"
  artifacts:
    - path: "supabase/functions/chat/sqlGenerator.ts"
      provides: "SQL generation with token usage in result"
      contains: "usage:"
    - path: "supabase/functions/chat/responseGenerator.ts"
      provides: "Response generation with token usage in result"
      contains: "usage:"
    - path: "supabase/functions/chat/pipeline.ts"
      provides: "Complete telemetry integration with timing capture"
      contains: "persistTelemetry"
  key_links:
    - from: "supabase/functions/chat/pipeline.ts"
      to: "supabase/functions/chat/telemetry.ts"
      via: "import and function call"
      pattern: "import.*telemetry"
    - from: "supabase/functions/chat/pipeline.ts"
      to: "supabase/functions/chat/sqlGenerator.ts"
      via: "usage extraction"
      pattern: "sqlResult\\.usage"
---

<objective>
Integrate telemetry capture into the chat pipeline by modifying generators to return token usage and updating the pipeline to capture timings and persist telemetry.

Purpose: Wire up the telemetry module from Plan 01 into the actual request flow, ensuring every chat interaction is logged with complete metrics.

Output:
- Modified `sqlGenerator.ts` that returns token usage from OpenAI response
- Modified `responseGenerator.ts` that returns token usage from streaming completion
- Modified `pipeline.ts` with timing capture, TTFB measurement, and telemetry persistence
</objective>

<execution_context>
@/Users/robsnider/.claude/get-shit-done/workflows/execute-plan.md
@/Users/robsnider/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/05-observability/CONTEXT.md
@.planning/phases/05-observability/05-RESEARCH.md
@.planning/phases/05-observability/05-01-SUMMARY.md
@supabase/functions/chat/sqlGenerator.ts
@supabase/functions/chat/responseGenerator.ts
@supabase/functions/chat/pipeline.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add token usage to SQL generator</name>
  <files>supabase/functions/chat/sqlGenerator.ts</files>
  <action>
Modify sqlGenerator.ts to capture and return token usage from OpenAI API response.

**Changes to GenerateSQLResult interface:**
Add new `usage` field:
```typescript
export interface GenerateSQLResult {
  parsed: NlToSqlResult;
  conversionId: string;
  usage: {
    inputTokens: number;
    outputTokens: number;
    cachedTokens: number;
  };
}
```

**Changes to generateSQL function:**

After the OpenAI response is received (`const response = await openai.responses.create({...})`), extract usage:
```typescript
const usage = {
  inputTokens: response.usage?.input_tokens ?? 0,
  outputTokens: response.usage?.output_tokens ?? 0,
  cachedTokens: response.usage?.input_tokens_details?.cached_tokens ?? 0,
};
```

Return usage in the result object.

**For self-correction path:** Also extract and return usage from the repair response when self-correction is triggered.

Keep existing functionality unchanged -- this is additive.
  </action>
  <verify>
Run: `deno check supabase/functions/chat/sqlGenerator.ts`
Verify the function signature and return type include usage.
  </verify>
  <done>
generateSQL returns GenerateSQLResult with usage containing inputTokens, outputTokens, cachedTokens from OpenAI API response.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add token usage to response generator</name>
  <files>supabase/functions/chat/responseGenerator.ts</files>
  <action>
Modify responseGenerator.ts to capture and return token usage from the streaming completion event.

**Changes to ResponseGeneratorResult interface:**
Add new `usage` field:
```typescript
export interface ResponseGeneratorResult {
  fullResponse: string;
  responseId: string;
  usage: {
    inputTokens: number;
    outputTokens: number;
    cachedTokens: number;
  };
}
```

**Changes to generateStreamingResponse function:**

Declare usage variable alongside responseId:
```typescript
let fullResponse = "";
let responseId = "";
let usage = { inputTokens: 0, outputTokens: 0, cachedTokens: 0 };
```

In the event loop, when handling `response.completed` event, extract usage:
```typescript
if (event.type === "response.completed") {
  responseId = event.response.id;
  usage = {
    inputTokens: event.response.usage?.input_tokens ?? 0,
    outputTokens: event.response.usage?.output_tokens ?? 0,
    cachedTokens: event.response.usage?.input_tokens_details?.cached_tokens ?? 0,
  };
}
```

Return usage in the result object.

Keep existing streaming behavior unchanged -- this is additive.
  </action>
  <verify>
Run: `deno check supabase/functions/chat/responseGenerator.ts`
Verify the function signature and return type include usage.
  </verify>
  <done>
generateStreamingResponse returns ResponseGeneratorResult with usage extracted from response.completed event.
  </done>
</task>

<task type="auto">
  <name>Task 3: Integrate telemetry capture into pipeline</name>
  <files>supabase/functions/chat/pipeline.ts</files>
  <action>
Modify pipeline.ts to capture timings, extract token usage from generators, and persist telemetry.

**Import telemetry module:**
```typescript
import { persistTelemetry, TelemetryRecord } from "./telemetry.ts";
```

**Initialize at start of async block:**
```typescript
const requestStart = performance.now();
let firstTextTime: number | null = null;

// Initialize telemetry record with known values
const telemetry: Partial<TelemetryRecord> = {
  userId,
  userQuestion: query,
  isOffTopic: false,
};
```

**After conversation setup:**
```typescript
telemetry.conversationId = conversationId;
```

**NL-to-SQL step timing and token capture:**
Wrap generateSQL call:
```typescript
const sqlStart = performance.now();
// ... existing generateSQL call ...
telemetry.nlToSqlDurationMs = Math.round(performance.now() - sqlStart);
telemetry.sqlModel = "gpt-4o-mini";
telemetry.sqlInputTokens = sqlResult.usage.inputTokens;
telemetry.sqlOutputTokens = sqlResult.usage.outputTokens;
telemetry.sqlCachedTokens = sqlResult.usage.cachedTokens;
```

**Off-topic handling:**
```typescript
if (sqlResult.parsed.offTopic) {
  telemetry.isOffTopic = true;
  telemetry.aiResponse = sqlResult.parsed.redirectMessage;
  // ... existing off-topic handling ...
}
```

**SQL capture (after validation succeeds):**
```typescript
telemetry.generatedSql = sqlResult.parsed.sqlQuery;
```

**SQL execution timing:**
```typescript
const execStart = performance.now();
// ... existing executeWithRLS call ...
telemetry.sqlExecutionDurationMs = Math.round(performance.now() - execStart);
telemetry.resultRowCount = queryResult.rows.length;
```

**Response generation timing and TTFB:**
Modify the onTextDelta callback to capture firstTextTime:
```typescript
onTextDelta: (delta) => {
  fullResponseText += delta;
  if (firstTextTime === null) {
    firstTextTime = performance.now();
  }
  // ... existing buffering logic ...
}
```

After response generation completes:
```typescript
telemetry.responseGenerationDurationMs = Math.round(performance.now() - respStart);
telemetry.ttfbMs = firstTextTime !== null
  ? Math.round(firstTextTime - requestStart)
  : null;
telemetry.responseModel = "gpt-4o-mini";
telemetry.responseInputTokens = responseUsage.inputTokens;
telemetry.responseOutputTokens = responseUsage.outputTokens;
telemetry.responseCachedTokens = responseUsage.cachedTokens;
telemetry.responseId = responseId;
telemetry.aiResponse = cleanContent;
telemetry.followUpSuggestions = followUps;
```

Note: destructure usage from generateStreamingResponse:
```typescript
const { responseId, usage: responseUsage } = await generateStreamingResponse({...});
```

**Error handling:**
In each catch block, populate error telemetry:
```typescript
// For NL-to-SQL errors:
telemetry.errorType = "sql_generation";
telemetry.errorMessage = String(err);
telemetry.failedStep = "understanding";

// For SQL execution errors:
telemetry.errorType = "sql_execution";
telemetry.errorMessage = String(err);
telemetry.failedStep = "looking_up";

// For response generation errors:
telemetry.errorType = "response_generation";
telemetry.errorMessage = String(err);
telemetry.failedStep = "response";

// For catch-all unexpected errors:
telemetry.errorType = "unexpected";
telemetry.errorMessage = String(err);
```

**SQL validation failure (already has console.error):**
```typescript
if (!validation.valid) {
  telemetry.errorType = "sql_validation";
  telemetry.errorMessage = validation.error ?? "Invalid SQL generated";
  telemetry.failedStep = "understanding";
  // ... existing error handling ...
}
```

**Persist telemetry in finally block:**
After `progress.close()`:
```typescript
finally {
  progress.close();
  // Fire-and-forget telemetry persistence
  persistTelemetry(telemetry as TelemetryRecord).catch((e) =>
    console.error("[Pipeline] Telemetry persistence failed:", e)
  );
}
```

**Important notes:**
- Keep telemetry as `Partial<TelemetryRecord>` and cast to full type at persist time (partial failures have nulls)
- Ensure TTFB uses absolute requestStart, not response generation start
- Do NOT await persistTelemetry -- fire and forget
  </action>
  <verify>
Run: `deno check supabase/functions/chat/pipeline.ts`
Verify telemetry import exists, timing capture at each step, and persistTelemetry call in finally block.
  </verify>
  <done>
pipeline.ts captures:
- Duration for NL-to-SQL, SQL execution, response generation
- TTFB from request start to first text delta
- Token usage from both OpenAI calls
- Error type and failed step for all error paths
- Persists telemetry via fire-and-forget in finally block
  </done>
</task>

</tasks>

<verification>
1. `deno check supabase/functions/chat/sqlGenerator.ts` passes
2. `deno check supabase/functions/chat/responseGenerator.ts` passes
3. `deno check supabase/functions/chat/pipeline.ts` passes
4. GenerateSQLResult includes `usage` with inputTokens, outputTokens, cachedTokens
5. ResponseGeneratorResult includes `usage` with inputTokens, outputTokens, cachedTokens
6. pipeline.ts imports persistTelemetry from telemetry.ts
7. pipeline.ts captures `performance.now()` for nlToSqlDurationMs, sqlExecutionDurationMs, responseGenerationDurationMs
8. pipeline.ts captures firstTextTime on first text_delta and computes ttfbMs
9. pipeline.ts calls persistTelemetry in finally block (fire-and-forget)
</verification>

<success_criteria>
- Phase 5 Success Criteria #1: Every user query produces a log record containing generated SQL (pipeline calls persistTelemetry with generatedSql)
- Phase 5 Success Criteria #2: Each log record includes three duration measurements (nlToSqlDurationMs, sqlExecutionDurationMs, responseGenerationDurationMs captured)
- Phase 5 Success Criteria #3: Each log record includes token usage counts for every OpenAI API call (sqlGenerator and responseGenerator return usage, pipeline captures them)
- Code compiles and maintains existing functionality
</success_criteria>

<output>
After completion, create `.planning/phases/05-observability/05-02-SUMMARY.md`
</output>
