---
phase: 04-conversation-discovery
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - supabase/functions/chat/index.ts
  - supabase/functions/chat/streamHandler.ts
  - supabase/functions/chat/prompts.ts
  - supabase/functions/chat/pipeline.ts
  - lib/features/chat/data/chat_suggested_prompt_repository.dart
  - lib/features/chat/presentation/providers/chat_starter_prompts_provider.dart
  - lib/features/chat/presentation/widgets/chat_empty_state.dart
autonomous: true

must_haves:
  truths:
    - "Edge function emits follow_up suggestions in the done SSE event"
    - "Starter questions are fetched from ai_insight_suggested_prompt table"
    - "Empty chat state shows dynamic prompts from Supabase, not hardcoded"
  artifacts:
    - path: "supabase/functions/chat/streamHandler.ts"
      provides: "DoneMessage with follow_up_suggestions field"
      contains: "follow_up_suggestions"
    - path: "supabase/functions/chat/prompts.ts"
      provides: "Follow-up generation instructions"
      contains: "FOLLOW_UP"
    - path: "lib/features/chat/data/chat_suggested_prompt_repository.dart"
      provides: "Repository to fetch starter prompts"
      contains: "ChatSuggestedPromptRepository"
    - path: "lib/features/chat/presentation/providers/chat_starter_prompts_provider.dart"
      provides: "Provider for starter prompts"
      contains: "@riverpod"
    - path: "lib/features/chat/presentation/widgets/chat_empty_state.dart"
      provides: "Dynamic starter questions UI"
      contains: "chatStarterPromptsProvider"
  key_links:
    - from: "supabase/functions/chat/pipeline.ts"
      to: "streamHandler.ts"
      via: "sendDone call with suggestions"
      pattern: "progress\\.sendDone"
    - from: "lib/features/chat/presentation/widgets/chat_empty_state.dart"
      to: "chat_starter_prompts_provider.dart"
      via: "ref.watch"
      pattern: "chatStarterPromptsProvider"
---

<objective>
Add follow-up suggestions to the done SSE event (not a separate event) and implement dynamic starter questions in the Flutter UI.

Purpose: Enable contextual follow-up suggestions after each AI response (CHAT-09) and dynamic starter questions on empty chat (DISC-01). Per user decision, follow-ups come with the done event.
Output: Edge function includes follow_up_suggestions in done event, Flutter fetches starter prompts from Supabase.
</objective>

<execution_context>
@/Users/robsnider/.claude/get-shit-done/workflows/execute-plan.md
@/Users/robsnider/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-conversation-discovery/04-CONTEXT.md

# Edge function code
@supabase/functions/chat/streamHandler.ts
@supabase/functions/chat/pipeline.ts
@supabase/functions/chat/prompts.ts
@supabase/functions/chat/responseGenerator.ts
@supabase/functions/chat/index.ts

# Flutter code
@lib/features/chat/presentation/widgets/chat_empty_state.dart
@supabase/migrations/20251224103300_ai_insight_suggested_prompts.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add follow-up suggestions to done SSE event</name>
  <files>
supabase/functions/chat/streamHandler.ts
supabase/functions/chat/prompts.ts
supabase/functions/chat/pipeline.ts
  </files>
  <action>
**Update streamHandler.ts:**

1. Modify DoneMessage interface to include follow-up suggestions:
```typescript
export interface DoneMessage {
  type: "done";
  follow_up_suggestions?: string[];
}
```

2. Update ProgressStream interface - modify sendDone to accept suggestions:
```typescript
/** Send completion signal with optional follow-up suggestions. */
sendDone(followUpSuggestions?: string[]): void;
```

3. Implement in createProgressStream return object:
```typescript
sendDone(followUpSuggestions?: string[]): void {
  const message: DoneMessage = { type: "done" };
  if (followUpSuggestions && followUpSuggestions.length > 0) {
    message.follow_up_suggestions = followUpSuggestions;
  }
  sendMessage(message);
},
```

**Update prompts.ts:**

Add follow-up instructions to RESPONSE_INSTRUCTIONS. Append after the existing instructions:

```typescript
// Add this constant
export const FOLLOW_UP_MARKER = "<!-- FOLLOW_UPS:";

// Add to RESPONSE_INSTRUCTIONS string (at the end):
`
FOLLOW-UP SUGGESTIONS:
- At the END of your response (after all content), add a JSON block with 2-3 follow-up question suggestions
- Format exactly: <!-- FOLLOW_UPS: ["Question 1?", "Question 2?", "Question 3?"] -->
- Keep questions brief (under 40 characters each)
- Make them contextually relevant to what was just discussed
- Vary question types: comparison ("vs last week?"), detail ("which day?"), trend ("any patterns?")
- Example: <!-- FOLLOW_UPS: ["How about last month?", "What day was best?", "Any patterns?"] -->
`
```

**Update pipeline.ts:**

1. Import FOLLOW_UP_MARKER from prompts.ts
2. Track fullResponseText by accumulating text deltas:
```typescript
let fullResponseText = "";
const { responseId } = await generateStreamingResponse({
  // ... existing params
  onTextDelta: (delta) => {
    fullResponseText += delta;
    // Strip follow-up marker from streamed text so it doesn't appear in UI
    const cleanDelta = delta.includes("<!-- FOLLOW_UPS:")
      ? delta.split("<!-- FOLLOW_UPS:")[0]
      : delta;
    if (cleanDelta) progress.sendTextDelta(cleanDelta);
  },
});
```

3. After streaming completes, extract and pass follow-ups to sendDone:
```typescript
// After progress.sendResponseId(responseId);

// Extract follow-up suggestions from accumulated response text
const followUps = extractFollowUpSuggestions(fullResponseText);
progress.sendDone(followUps);  // Pass suggestions to done event
```

4. Add helper function at bottom of file:
```typescript
/**
 * Extracts follow-up suggestions from the response text.
 * Looks for: <!-- FOLLOW_UPS: ["...", "..."] -->
 */
function extractFollowUpSuggestions(text: string): string[] {
  const marker = "<!-- FOLLOW_UPS:";
  const startIdx = text.indexOf(marker);
  if (startIdx === -1) return [];

  const endIdx = text.indexOf("-->", startIdx);
  if (endIdx === -1) return [];

  const jsonStr = text.slice(startIdx + marker.length, endIdx).trim();
  try {
    const parsed = JSON.parse(jsonStr);
    if (Array.isArray(parsed) && parsed.every(s => typeof s === "string")) {
      return parsed.slice(0, 3); // Max 3 suggestions
    }
  } catch {
    console.warn("[Pipeline] Failed to parse follow-up suggestions:", jsonStr);
  }
  return [];
}
```

IMPORTANT:
- The follow-up marker must NOT appear in the streamed text to the user. Filter it out during streaming.
- Follow-ups go IN the done event, not as a separate event type.
  </action>
  <verify>Deploy edge function locally with `supabase functions serve chat --env-file ./supabase/.env.local` and test with curl - done event should include follow_up_suggestions array</verify>
  <done>Edge function emits done SSE event with follow_up_suggestions array</done>
</task>

<task type="auto">
  <name>Task 2: Create starter prompts repository and provider</name>
  <files>
lib/features/chat/data/chat_suggested_prompt_repository.dart
lib/features/chat/presentation/providers/chat_starter_prompts_provider.dart
  </files>
  <action>
**Create lib/features/chat/data/chat_suggested_prompt_repository.dart:**

```dart
import 'package:logly/services/supabase_service.dart';
import 'package:riverpod_annotation/riverpod_annotation.dart';

part 'chat_suggested_prompt_repository.g.dart';

/// Repository for fetching starter question prompts from Supabase.
///
/// Reads from the existing `ai_insight_suggested_prompt` table.
class ChatSuggestedPromptRepository {
  ChatSuggestedPromptRepository(this._supabase);

  final SupabaseService _supabase;

  /// Fetches active starter prompts ordered by display_order.
  ///
  /// Returns a list of prompt strings to display in the empty chat state.
  Future<List<String>> getActivePrompts() async {
    final response = await _supabase.client
        .from('ai_insight_suggested_prompt')
        .select('prompt_text')
        .eq('is_active', true)
        .order('display_order');

    return (response as List<dynamic>)
        .map((row) => row['prompt_text'] as String)
        .toList();
  }
}

@Riverpod(keepAlive: true)
ChatSuggestedPromptRepository chatSuggestedPromptRepository(
  ChatSuggestedPromptRepositoryRef ref,
) {
  return ChatSuggestedPromptRepository(ref.watch(supabaseServiceProvider));
}
```

**Create lib/features/chat/presentation/providers/chat_starter_prompts_provider.dart:**

```dart
import 'package:logly/features/chat/data/chat_suggested_prompt_repository.dart';
import 'package:riverpod_annotation/riverpod_annotation.dart';

part 'chat_starter_prompts_provider.g.dart';

/// Provider for starter prompts shown in the empty chat state.
///
/// Fetches from Supabase on first access and caches the result.
/// Falls back to hardcoded prompts if the fetch fails.
@riverpod
Future<List<String>> chatStarterPrompts(ChatStarterPromptsRef ref) async {
  final repository = ref.watch(chatSuggestedPromptRepositoryProvider);

  try {
    final prompts = await repository.getActivePrompts();
    if (prompts.isNotEmpty) return prompts;
  } catch (e) {
    // Log error but don't crash - fall back to defaults
  }

  // Fallback prompts if fetch fails or returns empty
  return const [
    'What did I do this week?',
    'What are my most consistent habits?',
    'How active was I last month?',
  ];
}
```

Run build_runner after creating these files.
  </action>
  <verify>Run `fvm dart run build_runner build --delete-conflicting-outputs` - should generate .g.dart files for both</verify>
  <done>Repository fetches from ai_insight_suggested_prompt, provider caches result with fallback</done>
</task>

<task type="auto">
  <name>Task 3: Update ChatEmptyState to use dynamic prompts</name>
  <files>lib/features/chat/presentation/widgets/chat_empty_state.dart</files>
  <action>
Convert ChatEmptyState from StatelessWidget to ConsumerWidget to access Riverpod providers.

**Update lib/features/chat/presentation/widgets/chat_empty_state.dart:**

1. Import the provider:
```dart
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:logly/features/chat/presentation/providers/chat_starter_prompts_provider.dart';
```

2. Change class declaration:
```dart
class ChatEmptyState extends ConsumerWidget {
  const ChatEmptyState({required this.onSuggestionTap, super.key});

  final void Function(String question) onSuggestionTap;

  @override
  Widget build(BuildContext context, WidgetRef ref) {
```

3. Watch the provider and handle loading/error states:
```dart
final promptsAsync = ref.watch(chatStarterPromptsProvider);
```

4. In the Wrap children, replace hardcoded chips with:
```dart
...promptsAsync.when(
  data: (prompts) => prompts.map((prompt) => _SuggestionChip(
    label: prompt,
    onTap: () => onSuggestionTap(prompt),
  )).toList(),
  loading: () => [
    // Show shimmer placeholder chips during loading
    for (int i = 0; i < 3; i++)
      const _ShimmerChip(),
  ],
  error: (_, __) => [
    // Fallback to static prompts on error (provider already has fallback, but defensive)
    _SuggestionChip(
      label: 'What did I do this week?',
      onTap: () => onSuggestionTap('What did I do this week?'),
    ),
  ],
),
```

5. Add shimmer placeholder widget for loading state:
```dart
class _ShimmerChip extends StatelessWidget {
  const _ShimmerChip();

  @override
  Widget build(BuildContext context) {
    final theme = Theme.of(context);
    return Container(
      width: 180,
      height: 36,
      decoration: BoxDecoration(
        color: theme.colorScheme.surfaceContainerHighest.withOpacity(0.5),
        borderRadius: BorderRadius.circular(20),
      ),
    );
  }
}
```

The shimmer chips keep the same visual shape as real chips, providing a smooth loading experience.
  </action>
  <verify>Run the app and navigate to chat screen with no messages - should show prompts from Supabase (or fallback if network issue)</verify>
  <done>ChatEmptyState fetches dynamic prompts from Supabase, shows shimmer during loading, falls back to hardcoded on error</done>
</task>

</tasks>

<verification>
1. Done event has follow_up_suggestions: grep "follow_up_suggestions" supabase/functions/chat/streamHandler.ts
2. Pipeline extracts follow-ups: grep "extractFollowUpSuggestions" supabase/functions/chat/pipeline.ts
3. Repository exists: ls lib/features/chat/data/chat_suggested_prompt_repository.dart
4. Provider exists: ls lib/features/chat/presentation/providers/chat_starter_prompts_provider.dart
5. ChatEmptyState uses provider: grep "chatStarterPromptsProvider" lib/features/chat/presentation/widgets/chat_empty_state.dart
6. Codegen passes: `fvm dart run build_runner build --delete-conflicting-outputs` exits 0
7. No analyzer errors: `fvm flutter analyze`
</verification>

<success_criteria>
- Edge function done event includes follow_up_suggestions array (not separate event)
- Follow-up suggestions extracted from response text (marker stripped from UI)
- Starter prompts fetched from ai_insight_suggested_prompt table
- ChatEmptyState shows dynamic prompts with loading shimmer
- Fallback prompts work when Supabase fetch fails
- Zero analyzer errors
</success_criteria>

<output>
After completion, create `.planning/phases/04-conversation-discovery/04-02-SUMMARY.md`
</output>
